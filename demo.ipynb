{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mrcnn\n",
    "import mrcnn.config\n",
    "import mrcnn.model\n",
    "import mrcnn.visualize\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# load the class label names from disk, one label per line\n",
    "# CLASS_NAMES = open(\"coco_labels.txt\").read().strip().split(\"\\n\")\n",
    "\n",
    "CLASS_NAMES = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "class SimpleConfig(mrcnn.config.Config):\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"coco_inference\"\n",
    "    \n",
    "    # set the number of GPUs to use along with the number of images per GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "\t# Number of classes = number of classes + 1 (+1 for the background). The background class is named BG\n",
    "    NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# Initialize the Mask R-CNN model for inference and then load the weights.\n",
    "# This step builds the Keras model architecture.\n",
    "model = mrcnn.model.MaskRCNN(mode=\"inference\", \n",
    "                             config=SimpleConfig(),\n",
    "                             model_dir=os.getcwd())\n",
    "\n",
    "# Load the weights into the model.\n",
    "# Download the mask_rcnn_coco.h5 file from this link: https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
    "model.load_weights(filepath=\"mask_rcnn_coco.h5\", \n",
    "                   by_name=True)\n",
    "\n",
    "# load the input image, convert it from BGR to RGB channel\n",
    "image = cv2.imread(\"sample_image.jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Perform a forward pass of the network to obtain the results\n",
    "r = model.detect([image], verbose=0)\n",
    "\n",
    "# Get the results for the first image.\n",
    "r = r[0]\n",
    "\n",
    "# Visualize the detected objects.\n",
    "mrcnn.visualize.display_instances(image=image, \n",
    "                                  boxes=r['rois'], \n",
    "                                  masks=r['masks'], \n",
    "                                  class_ids=r['class_ids'], \n",
    "                                  class_names=CLASS_NAMES, \n",
    "                                  scores=r['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION='python'\n",
    "import tensorflow as tf\n",
    "gpu_available = tf.test.is_gpu_available()\n",
    "is_cuda_gpu_available = tf.test.is_gpu_available(cuda_only=True)\n",
    "is_cuda_gpu_min_3 = tf.test.is_gpu_available(True, (3,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_cuda_gpu_available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "## For visualizing results\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "def sem_seg_data_gen(ann_path, img_dir, batch_size, input_image_size, mask_type):\n",
    "    '''\n",
    "    Data generator for semantic segmentation\n",
    "    '''\n",
    "    \n",
    "    def filterDataset(ann_path, classes, ):    \n",
    "        # initialize COCO api for instance annotations\n",
    "        annFile = ann_path\n",
    "        coco = COCO(annFile)\n",
    "        \n",
    "        images = []\n",
    "        if classes!=None:\n",
    "            # iterate for each individual class in the list\n",
    "            for className in classes:\n",
    "                # get all images containing given categories\n",
    "                catIds = coco.getCatIds(catNms=className)\n",
    "                imgIds = coco.getImgIds(catIds=catIds)\n",
    "                images += coco.loadImgs(imgIds)\n",
    "        \n",
    "        else:\n",
    "            imgIds = coco.getImgIds()\n",
    "            images = coco.loadImgs(imgIds)\n",
    "        \n",
    "        # Now, filter out the repeated images\n",
    "        unique_images = []\n",
    "        for i in range(len(images)):\n",
    "            if images[i] not in unique_images:\n",
    "                unique_images.append(images[i])\n",
    "                \n",
    "        random.shuffle(unique_images)\n",
    "        dataset_size = len(unique_images)\n",
    "        \n",
    "        return unique_images, dataset_size, coco\n",
    "    \n",
    "    coco = COCO(ann_path)\n",
    "    \n",
    "    catIDs = coco.getCatIds()\n",
    "    cats = coco.loadCats(catIDs)\n",
    "\n",
    "    nms=[cat['name'] for cat in cats]\n",
    "    print(len(nms),'COCO categories: \\n{}\\n'.format(', '.join(nms)))\n",
    "\n",
    "    nms = set([cat['supercategory'] for cat in cats])\n",
    "    print(len(nms),'COCO supercategories: \\n{}'.format(' '.join(nms)))\n",
    "    \n",
    "    classes = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', \n",
    "               'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', \n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',\n",
    "               'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "               'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "               'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant',\n",
    "               'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "               'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "    \n",
    "    def getClassName(classID, cats):\n",
    "        for i in range(len(cats)):\n",
    "            if cats[i]['id']==classID:\n",
    "                return cats[i]['name']\n",
    "        return None\n",
    "\n",
    "    def getImage(imageObj, img_folder, input_image_size):\n",
    "        # Read and normalize an image\n",
    "        train_img = io.imread(img_folder + '/' + imageObj['file_name'])/255.0\n",
    "        # Resize\n",
    "        train_img = cv2.resize(train_img, input_image_size)\n",
    "        if (len(train_img.shape)==3 and train_img.shape[2]==3): # If it is a RGB 3 channel image\n",
    "            return train_img\n",
    "        else: # To handle a black and white image, increase dimensions to 3\n",
    "            stacked_img = np.stack((train_img,)*3, axis=-1)\n",
    "            return stacked_img\n",
    "    \n",
    "    def getNormalMask(imageObj, classes, coco, catIds, input_image_size):\n",
    "        annIds = coco.getAnnIds(imageObj['id'], catIds=catIds, iscrowd=None)\n",
    "        anns = coco.loadAnns(annIds)\n",
    "        cats = coco.loadCats(catIds)\n",
    "        train_mask = np.zeros(input_image_size)\n",
    "        for a in range(len(anns)):\n",
    "            className = getClassName(anns[a]['category_id'], cats)\n",
    "            #print(className)\n",
    "            pixel_value = classes.index(className)+1\n",
    "            new_mask = cv2.resize(coco.annToMask(anns[a])*pixel_value, input_image_size)\n",
    "            train_mask = np.maximum(new_mask, train_mask)\n",
    "\n",
    "        # Add extra dimension for parity with train_img size [X * X * 3]\n",
    "        train_mask = train_mask.reshape(input_image_size[0], input_image_size[1], 1)\n",
    "        return train_mask  \n",
    "    \n",
    "    def getBinaryMask(imageObj, coco, catIds, input_image_size):\n",
    "        annIds = coco.getAnnIds(imageObj['id'], catIds=catIds, iscrowd=None)\n",
    "        anns = coco.loadAnns(annIds)\n",
    "        train_mask = np.zeros(input_image_size)\n",
    "        for a in range(len(anns)):\n",
    "            new_mask = cv2.resize(coco.annToMask(anns[a]), input_image_size)\n",
    "            \n",
    "            #Threshold because resizing may cause extraneous values\n",
    "            new_mask[new_mask >= 0.5] = 1\n",
    "            new_mask[new_mask < 0.5] = 0\n",
    "\n",
    "            train_mask = np.maximum(new_mask, train_mask)\n",
    "\n",
    "        # Add extra dimension for parity with train_img size [X * X * 3]\n",
    "        train_mask = train_mask.reshape(input_image_size[0], input_image_size[1], 1)\n",
    "        return train_mask\n",
    "\n",
    "\n",
    "    def dataGeneratorCoco(images, classes, coco, folder, \n",
    "                        input_image_size=(224,224), batch_size=4, mask_type='binary'):\n",
    "        \n",
    "        img_folder = '{}'.format(folder)\n",
    "        dataset_size = len(images)\n",
    "        catIds = coco.getCatIds(catNms=classes)\n",
    "        \n",
    "        c = 0\n",
    "        while(True):\n",
    "            img = np.zeros((batch_size, input_image_size[0], input_image_size[1], 3)).astype('float')\n",
    "            mask = np.zeros((batch_size, input_image_size[0], input_image_size[1], 1)).astype('float')\n",
    "\n",
    "            for i in range(c, c+batch_size): #initially from 0 to batch_size, when c = 0\n",
    "                imageObj = images[i]\n",
    "                \n",
    "                ### Retrieve Image ###\n",
    "                #print(imageObj)\n",
    "                train_img = getImage(imageObj, img_folder, input_image_size)\n",
    "                \n",
    "                ### Create Mask ###\n",
    "                if mask_type==\"binary\":\n",
    "                    train_mask = getBinaryMask(imageObj, coco, catIds, input_image_size)\n",
    "                \n",
    "                elif mask_type==\"normal\":\n",
    "                    train_mask = getNormalMask(imageObj, classes, coco, catIds, input_image_size)                \n",
    "                \n",
    "                # Add to respective batch sized arrays\n",
    "                img[i-c] = train_img\n",
    "                mask[i-c] = train_mask\n",
    "                \n",
    "            c+=batch_size\n",
    "            if(c + batch_size >= dataset_size):\n",
    "                c=0\n",
    "                random.shuffle(images)\n",
    "            \n",
    "            assert not np.any(np.isnan(img))\n",
    "            assert not np.any(np.isnan(mask))\n",
    "            \n",
    "            yield img, mask/255\n",
    "            \n",
    "        \n",
    "    images, dataset_size, coco = filterDataset(ann_path, classes,)\n",
    "    \n",
    "    data_gen = dataGeneratorCoco(images, classes, coco, img_dir,\n",
    "                            input_image_size, batch_size, mask_type)\n",
    "    \n",
    "    return data_gen, dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=16.08s)\n",
      "creating index...\n",
      "index created!\n",
      "80 COCO categories: \n",
      "person, bicycle, car, motorcycle, airplane, bus, train, truck, boat, traffic light, fire hydrant, stop sign, parking meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard, surfboard, tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, couch, potted plant, bed, dining table, toilet, tv, laptop, mouse, remote, keyboard, cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair drier, toothbrush\n",
      "\n",
      "12 COCO supercategories: \n",
      "vehicle accessory person outdoor sports animal appliance furniture electronic food kitchen indoor\n",
      "loading annotations into memory...\n",
      "Done (t=16.33s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=7.29s)\n",
      "creating index...\n",
      "index created!\n",
      "80 COCO categories: \n",
      "person, bicycle, car, motorcycle, airplane, bus, train, truck, boat, traffic light, fire hydrant, stop sign, parking meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard, surfboard, tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, couch, potted plant, bed, dining table, toilet, tv, laptop, mouse, remote, keyboard, cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair drier, toothbrush\n",
      "\n",
      "12 COCO supercategories: \n",
      "vehicle accessory person outdoor sports animal appliance furniture electronic food kitchen indoor\n",
      "loading annotations into memory...\n",
      "Done (t=9.56s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "train_sem_seg_gen, train_dataset_size = sem_seg_data_gen(ann_path=r'D:\\Nirwan\\PANet\\foo-upgraded\\coco\\annotations\\instances_train2014.json',\n",
    "                                             img_dir=r'D:\\Nirwan\\PANet\\foo-upgraded\\coco\\train2014',\n",
    "                                             batch_size=4, input_image_size=(128,128), mask_type='normal')\n",
    "val_sem_seg_gen, val_dataset_size = sem_seg_data_gen(ann_path=r'D:\\Nirwan\\PANet\\foo-upgraded\\coco\\annotations\\instances_val2014.json',\n",
    "                                             img_dir=r'D:\\Nirwan\\PANet\\foo-upgraded\\coco\\val2014',\n",
    "                                             batch_size=4, input_image_size=(128,128), mask_type='normal')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_advanced_segmentation_models as tasm\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE_NAME = \"resnet50\"\n",
    "WEIGHTS = \"imagenet\"\n",
    "HEIGHT = 128\n",
    "WIDTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model, layers, layer_names = tasm.create_base_model(name=BACKBONE_NAME, weights=WEIGHTS, height=HEIGHT, width=WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'conv1_relu_1/Identity:0' shape=(None, 64, 64, 64) dtype=float32>,\n",
       " <tf.Tensor 'conv2_block3_out_1/Identity:0' shape=(None, 32, 32, 256) dtype=float32>,\n",
       " <tf.Tensor 'conv3_block4_out_1/Identity:0' shape=(None, 16, 16, 512) dtype=float32>,\n",
       " <tf.Tensor 'conv4_block6_out_1/Identity:0' shape=(None, 8, 8, 1024) dtype=float32>,\n",
       " <tf.Tensor 'conv5_block3_out_1/Identity:0' shape=(None, 4, 4, 2048) dtype=float32>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.SGD(learning_rate=0.2, momentum=0.9)\n",
    "metrics = [tasm.metrics.IOUScore(threshold=0.5)]\n",
    "categorical_focal_dice_loss = tasm.losses.CategoricalFocalLoss(alpha=0.25, gamma=2.0) #+ tasm.losses.DiceLoss(class_weights=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tasm.HRNetOCR(n_classes=80,)\n",
    "model.compile(tf.keras.optimizers.Adam(0.0001), loss=categorical_focal_dice_loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:5'):\n",
    "    history = model.fit_generator(\n",
    "        train_sem_seg_gen,\n",
    "        epochs=10,\n",
    "        steps_per_epoch=1000,\n",
    "        validation_data=val_sem_seg_gen,\n",
    "        validation_steps=50\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tensorflow12')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "593edca81efdc0ba87cb5a20a3aa1566136ed5648d87d5dafbd4ce8a45c89f06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
